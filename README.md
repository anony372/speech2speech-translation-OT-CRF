# speech2speech-translation-OT-CRF

This repository features a comprehensive Python-based audio processing pipeline designed to perform seamless audio translation and synthesis. The pipeline begins by extracting speech features from raw audio using the Wav2Vec2 model. These features are then translated from the source language to the target language using the SeamlessM4T model. To model the sequence of translated features, Conditional Random Fields (CRF) are employed, which help predict the most likely sequence of labels representing the speech content. Following this, Tacotron2, a powerful acoustic decoding model, converts the sequence labels into a mel-spectrogram that captures the acoustic properties of the translated speech. To ensure that the generated audio aligns with the desired acoustic features, the mel-spectrogram is further refined through Optimal Transport alignment with a reference distribution. Finally, a vocoder synthesizes the aligned mel-spectrogram into the final synthetic audio output. The pipeline also visualizes the aligned mel-spectrogram, allowing users to examine the acoustic alignment. This project requires several dependencies, including PyTorch, transformers, torchaudio, scikit-learn, scipy, matplotlib, huggingface_hub, and soundfile. 
